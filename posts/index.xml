<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Posts on Onemore118</title>
    <link>https://onemore118.github.io/posts/</link>
    <description>Recent content in Posts on Onemore118</description>
    <image>
      <title>Onemore118</title>
      <url>https://onemore118.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>https://onemore118.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sat, 14 Oct 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://onemore118.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>货币</title>
      <link>https://onemore118.github.io/posts/%E8%B4%A7%E5%B8%81/</link>
      <pubDate>Sat, 14 Oct 2023 00:00:00 +0000</pubDate>
      
      <guid>https://onemore118.github.io/posts/%E8%B4%A7%E5%B8%81/</guid>
      <description>货币需要进行一个扩张与收缩的潮汐运动才能维持一个符合经济规律的平衡，即货币的周期性规律。 所以货币发行需要锚点某种标地物或者说是蓄水池。布雷顿森林体系之前是黄金，现在是国家信用叠加大宗商品，中国在一定时期是房地产，美国则是石油和科技。
扩张的货币必须通过某个东西将其吸收，以维护其刺激经济行为后的物价稳定。由于货币的定价属性，锚点物的价格必然会被抬高。
考虑到扩张经济行为的需要，定在石油黄金等天然物或者比特币这类算法产物虽然可以维护币值稳定，但是作为刺激经济的工具将受到极大限制。如果定在房地产又会造成房价走高而带来一系列社会问题，同时由于房地产的人造属性，又反过来作为信用扩张工具加速了货币的扩张，非但没有作为蓄水池的作用，反而成为了印钞机。如果锚定在国债这类信用债券，在一定时期内可以通过新债换旧债，但是这是在赌经济的发展速度要快于偿还债务的利息。如果将货币锚定在科技，这类高风险且很难在短期定价的东西又使得很难具备可操作性。
人类至今都没有找到一个合适的方法来兼顾经济扩张与货币稳定。只能寄希望于科学与技术的发展，使得经济的发展速度要快于货币的扩张速度，这样才能兼顾两个目标。
不过从政治经济学的角度思考，经济是否非得追求增长，比起持续的增长，发展的均衡是不是更重要。 这里就涉及到公平与效率和生产力与生产关系的矛盾关系。所谓蛋糕做大，并不应该追求货币总量的扩张，而是购买力，购买力来源于生产力，生产力来源科技进步，生产力影响生产关系，生产关系的调节又会影响生产力的积极性。这些是传统的政治经济学概念。
可想想 AI 发展带来的变革，与其整日担忧被 AI 替代，不如想想 AI 如果作为一种可以替代人类的生产力，那么人类将超越传统的生产关系与生产力的矛盾关系，变成处理均衡的问题了。那么我们是不是就可以进入共产主义社会了。
生产力由 AI 来进行生产，而人则可以享受发展带来的好处，那时货币仅作为定价而不作为资本工具，这是真正的大同社会啊！
当然这是发展的理想终极形态，这中间会有一段阵痛期，那就是会 AI 与不会的人之间的差异扩大，这将加剧社会发展的不平衡，不过这是政府需要考虑的事情，作为个人，我们需要积极拥抱 AI，在等待大同社会来临之前，先做不被淘汰的人。等 AI 开始普惠全人类的时候，竞争也行就不会这么残酷了。想想互联网发展之初带来的不平衡，到现在互联网开始普惠，人与人之间的差距理论上来说是被缩小，只不过生产关系的变革是缓慢的，而这里面又有很多政府等人为因素在里面，会有很多问题，但是总体方向是一个向上向好的方向发展。</description>
    </item>
    
    <item>
      <title>信息战场</title>
      <link>https://onemore118.github.io/posts/%E4%BF%A1%E6%81%AF%E6%88%98%E5%9C%BA/</link>
      <pubDate>Sun, 17 Sep 2023 00:00:00 +0000</pubDate>
      
      <guid>https://onemore118.github.io/posts/%E4%BF%A1%E6%81%AF%E6%88%98%E5%9C%BA/</guid>
      <description>虽然很早之前就听过“增长黑客”这个词，但是直到今天看了光年实验室的几篇推文，才对这个词有了更深刻的了解，同时也突然意识到，原来在增长这个领域，有如此深刻的东西可以研究。
首先，这里的增长更多是指通过信息技术手段，实现产品或服务的用户增长。也就是说，我们面对的战场，是信息战场，也可称作数字空间。
那么如果想在信息战场打胜战，就必须研究信息战场和信息战争的特点，否则不可能取得大胜，并且不同战场有不同战场的规律，比如在微信的战场和在抖音的战场，国内战场和国外战场就必然有很大的不同。但是这里面也一定有一些普遍的规律存在，只不过要时刻提醒自己，具体问题要具体分析。
当务之急，需要研究信息战场的特点和斗争对象。
信息战场的特点 首先，信息战场的特点，既然是战场，那必然涉及到时空二元。
信息战场的空间特点 就空间而言，从宏观上讲，信息的空间具有无限性，其实比较贴切的说法是虚拟性和无界性。但是就具体平台上，空间又具有有限性。信息无限性很好理解，也是很多人第一感觉，其无限性使其能够超越时空，能够穿越时间的限制，无止境向前运动。
着重应该讨论的是空间的有限性，有限性体现在：
第一，无论是内容流还是搜索流，都是在一定的平台上展示，虽然链接可以在平台间互相跳转，但是考虑到平台的割裂性以及各个平台的主动隔离，信息都是在特定平台上展示的。
第二，信息在平台以一定形式展现，如微信公众号文章以文章流展示，抖音视频以视频流形式展示，既然信息最后要以用户作为接收方，那么就需要考虑到接收者的接收形式。而接收的信息除了在手机屏幕上具备一定的空间局限性外，还在算法推荐上会涉及到地理空间（数据空间局限带来的地理空间割裂）、年龄、兴趣爱好、社交关系、平台规则、法律法规、网络等的局限。
总结一下就是，空间有限性体现在平台有限性，媒介有限性和数字有限性。
信息战场的时间特点 就时间而言，信息的传播与消费可以超越时间限制，但是信息的消费曲线有两方面的时间约束：
第一，算法带来的时间约束，信息的发布时间、社交关系或者付费推广，往往会影响算法推荐，从而影响用户消费。
第二，内容带来的时间约束，更多的点赞收藏转发评论会带来更多的消费增长，或者SEO做的好也会带来消费。
也即是说，信息战场看似无限的时间衍生，其实会被算法和内容质量约束而无法实现价值。且内容对用户时间的争夺上最终会使得好内容被长期看到，而99%的内容会以比特形态静躺在服务器上而不被消费。
信息战场的斗争对象 讨论信息战场的斗争对象对于战略战术的应用有着更深刻的影响。信息战场的特点是应该被我们所利用，要加强利用优势特点为我所用，同时规避其缺点。但是斗争的形式往往随斗争对象的改变而改变，所以需要加强研究，同时丰富研究手段。
信息战场的处理对象是信息，博弈对象是平台算法和其他竞争者。
处理对象 处理对象是信息，那我们就需要运用信息论的方法去研究事物，这样才能找到信息的规律。信息方法论涉及信息的编码、信息熵（也就是信息不确定性或者叫信息量）、矢量化（信息的投射维度）、冗余度、等价性、信息增量、压缩比和失真率、信息正交性（叠加与删除）、互信息（相关性）、条件熵和信息增益、交叉熵（信息误判的损失）、信噪比、噪声、信道、信道容量。
信息虽然展示方式多样，包括文字、视频、音频、图片等，但是以目前的技术手段，因为平台分发信息的依据最为高效直接的还是处理文字（包括数字），所以研究博弈对象应该着重研究其对文字的利用，辅之以内容、合作对象、分发平台的研究。研究关键词的利用可以起到四两拨千斤的作用。
通过对各平台专利的研究，也可以知道，目前对视频内容的分发维度包括视频标题、hashtag、视频音频文字、视频内容画面、视频内容画面出现的文字、发布时间频率、互动数据等。后面有机会专门写一篇博客介绍下平台如何分发内容。
博弈对象 另外平台算法，这里有个误区，觉得研究平台漏洞就可以实现增长，其实这个是被无数人证明是个错误的理念。不应该去研究平台漏洞，我们永远要相信平台的设计者是个聪明的人。但是这不代表我们就不研究平台的规则。只不过我们在熟悉平台规则外，最重要的站在平台的立场去思考平台用户，因为平台用户是平台赖以生存的根基，平台服务好用户才有平台生存的可能。所以我们也要跟平台一样，去研究平台的用户，去思考平台是如何给用户带来价值的，从而利用它们，发力点仍是用户。</description>
    </item>
    
    <item>
      <title>信息与能量</title>
      <link>https://onemore118.github.io/posts/%E4%BF%A1%E6%81%AF%E4%B8%8E%E8%83%BD%E9%87%8F/</link>
      <pubDate>Fri, 01 Sep 2023 00:00:00 +0000</pubDate>
      
      <guid>https://onemore118.github.io/posts/%E4%BF%A1%E6%81%AF%E4%B8%8E%E8%83%BD%E9%87%8F/</guid>
      <description>信息与能量的关系 当你知道信息熵和热力熵是同一个公式的时候，你就会明白为什么在这个时代，信息行业能够造成如此巨大的影响。因为信息即是能量，那些码代码的工程师实际上是在控制能量。所以决定企业的体量就在于控制信息量的大小。
为什么OpenAI 在今天能够达到这么高的估值，主要的原因在于其几乎学会了控制整个互联网的信息。而 Google 作为上个二十年的巨无霸企业，在如今却像是掌控铀的原材料国，却尚无一手开发资源的能力。二者掌控的能量现在好比铀与原子弹的差距。
但是 openai 绝非高枕无忧，一方面运行 GPT 需要负担高额成本，另一方面学会造原子弹的机构越来越多。同时，GPT 现在就像原子弹一样不可控，只能靠一大堆约束技术加以限制。
因此，这里可以做个预判，下一个时代的巨无霸，其核心能力将在于能否将 LLM 加以合理控制，即像是 GPT 现在还是核聚变，而我们要做的是，实现可控核聚变。
References [1] 张首晟-第一性原理与创业</description>
    </item>
    
    <item>
      <title>论智能</title>
      <link>https://onemore118.github.io/posts/llms%E7%9A%84%E5%B1%80%E9%99%90%E6%80%A7/</link>
      <pubDate>Fri, 01 Sep 2023 00:00:00 +0000</pubDate>
      
      <guid>https://onemore118.github.io/posts/llms%E7%9A%84%E5%B1%80%E9%99%90%E6%80%A7/</guid>
      <description>LLMs的局限 如果要谈及LLMs的局限，我们需要先了解下LLMs的工作原理。
GPT4 是一个巨型的因果归纳器，而不是因果演绎器，它的原理是归纳语句的因果的关系，在上下文语境中预测单词，这种带有概率性质的符号模型，使其具备对这个世界有着模糊的认知。但这绝非智能，且非通往智能的道路。
首先，文字符号作为信道小传输效率高的一种符号学，本身是人类表达的一种很小的模式之一，它在人类历史中也不过短短几千年，比如一段单词&amp;quot;哈&amp;quot;，用不同语气表达都具有不同的含义，但是 llm 是不懂的。另一方面，llm 只能归纳预测下一个单词的行为，使其无法理解人类社会现存的规范和情感，这也就是其胡说八道口无遮拦的原因。
智能 何为智能？智能是一种非常普遍的心理能力，包括推理能力、计划能力、解决问题的能力、抽象思维能力、理解复杂思想的能力、快速学习的能力以及从经验中学习的能力。
谈及智能，有个能力是必须具备的，那就是因果演绎的能力，智能体提供多种感官感知世界，再将世界内化为生产知识，通过知识，又能做出假设然后演绎归纳新知识，而不是单纯接受数据归纳数据。
何以利用LLMs改造世界 但是另外的方面，打工人的不少工作其实就是符号学的运用，比如打代码写稿子，通过 gpt4 可以很好的完成部分跟符号归纳的工作，但是还替代不了人类，因为人类的演绎能力是 gpt4 不具备的，所以我们才只称其为 copilot。
用辩证法的否定之否定来判定，我们要利用 gpt4 的归纳和符号运用能力，而使用人类独有的演绎能力来驾驭它。
References [1] AI Chatbots Don’t Care About Your Social Norms
[2] LeCun再泼冷水：只会看书的语言模型永远无法实现类人智能
[3] AGI离我们还有多远？大模型不是最终解，世界模型才是未来</description>
    </item>
    
  </channel>
</rss>
