<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Posts on Onemore118</title>
    <link>https://onemore118.github.io/posts/</link>
    <description>Recent content in Posts on Onemore118</description>
    <image>
      <title>Onemore118</title>
      <url>https://onemore118.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>https://onemore118.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Fri, 01 Sep 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://onemore118.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>信息与能量</title>
      <link>https://onemore118.github.io/posts/%E4%BF%A1%E6%81%AF%E4%B8%8E%E8%83%BD%E9%87%8F/</link>
      <pubDate>Fri, 01 Sep 2023 00:00:00 +0000</pubDate>
      
      <guid>https://onemore118.github.io/posts/%E4%BF%A1%E6%81%AF%E4%B8%8E%E8%83%BD%E9%87%8F/</guid>
      <description>信息与能量的关系 当你知道信息熵和热力熵是同一个公式的时候，你就会明白为什么在这个时代，信息行业能够造成如此巨大的影响。因为信息即是能量，那些码代码的工程师实际上是在控制能量。所以决定企业的体量就在于控制信息量的大小。
为什么OpenAI 在今天能够达到这么高的估值，主要的原因在于其几乎学会了控制整个互联网的信息。而 Google 作为上个二十年的巨无霸企业，在如今却像是掌控铀的原材料国，却尚无一手开发资源的能力。二者掌控的能量现在好比铀与原子弹的差距。
但是 openai 绝非高枕无忧，一方面运行 GPT 需要负担高额成本，另一方面学会造原子弹的机构越来越多。同时，GPT 现在就像原子弹一样不可控，只能靠一大堆约束技术加以限制。
因此，这里可以做个预判，下一个时代的巨无霸，其核心能力将在于能否将 LLM 加以合理控制，即像是 GPT 现在还是核聚变，而我们要做的是，实现可控核聚变。
References [1] 张首晟-第一性原理与创业</description>
    </item>
    
    <item>
      <title>论智能</title>
      <link>https://onemore118.github.io/posts/llms%E7%9A%84%E5%B1%80%E9%99%90%E6%80%A7/</link>
      <pubDate>Fri, 01 Sep 2023 00:00:00 +0000</pubDate>
      
      <guid>https://onemore118.github.io/posts/llms%E7%9A%84%E5%B1%80%E9%99%90%E6%80%A7/</guid>
      <description>LLMs的局限 如果要谈及LLMs的局限，我们需要先了解下LLMs的工作原理。
GPT4 是一个巨型的因果归纳器，而不是因果演绎器，它的原理是归纳语句的因果的关系，在上下文语境中预测单词，这种带有概率性质的符号模型，使其具备对这个世界有着模糊的认知。但这绝非智能，且非通往智能的道路。
首先，文字符号作为信道小传输效率高的一种符号学，本身是人类表达的一种很小的模式之一，它在人类历史中也不过短短几千年，比如一段单词&amp;quot;哈&amp;quot;，用不同语气表达都具有不同的含义，但是 llm 是不懂的。另一方面，llm 只能归纳预测下一个单词的行为，使其无法理解人类社会现存的规范和情感，这也就是其胡说八道口无遮拦的原因。
智能 何为智能？智能是一种非常普遍的心理能力，包括推理能力、计划能力、解决问题的能力、抽象思维能力、理解复杂思想的能力、快速学习的能力以及从经验中学习的能力。
谈及智能，有个能力是必须具备的，那就是因果演绎的能力，智能体提供多种感官感知世界，再将世界内化为生产知识，通过知识，又能做出假设然后演绎归纳新知识，而不是单纯接受数据归纳数据。
何以利用LLMs改造世界 但是另外的方面，打工人的不少工作其实就是符号学的运用，比如打代码写稿子，通过 gpt4 可以很好的完成部分跟符号归纳的工作，但是还替代不了人类，因为人类的演绎能力是 gpt4 不及备的，所以我们才只称其为 copilot。
用辩证法的否定之否定来判定，我们要利用 gpt4 的归纳和符号运用能力，而使用人类独有的演绎能力来驾驭它。
References [1] AI Chatbots Don’t Care About Your Social Norms
[2] LeCun再泼冷水：只会看书的语言模型永远无法实现类人智能</description>
    </item>
    
  </channel>
</rss>
